# CSD-Audio-Only
### Concurrent Speaker Detection: A Multi-Microphone Transformer-Based Approach

This repository contains the code for the **audio-only model** presented in the paper:  
ğŸ“„ **"Concurrent Speaker Detection: A Multi-Microphone Transformer-Based Approach"**  
ğŸ”— [Link to Paper](https://ieeexplore.ieee.org/document/10715386)  

## ğŸ“Œ Overview
This model classifies audio segments into three categories:

1ï¸âƒ£ **Noise only**  
2ï¸âƒ£ **Single-speaker activity**  
3ï¸âƒ£ **Concurrent-speaker activity**  

The method was evaluated on **AMI, AliMeeting, and CHiME-5** datasets, demonstrating state-of-the-art results.  



## ğŸ“„ Citation  
If you use this work, please cite:

@INPROCEEDINGS{10715386,
  author={Eliav, Amit and Gannot, Sharon},
  booktitle={2024 32nd European Signal Processing Conference (EUSIPCO)}, 
  title={Concurrent Speaker Detection: A Multi-Microphone Transformer-Based Approach}, 
  year={2024},
  volume={},
  number={},
  pages={897-901},
  keywords={Training;Databases;Noise;Europe;Transformers;Data models;Calibration},
  doi={10.23919/EUSIPCO63174.2024.10715386}}

  ```bibtex
@article{eliav202Xcsd,
  author    = {Amit Eliav and Sharon Gannot},
  title     = {Concurrent Speaker Detection: A Multi-Microphone Transformer-Based Approach},
  journal   = {Conference/Journal Name},
  year      = {202X}
}
